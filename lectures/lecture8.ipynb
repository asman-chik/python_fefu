{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Курс Python. Занятие 8. Практика по нейронным сетям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ссылка на блокнот в Google Drive для открытия в Google Colab](https://drive.google.com/open?id=1kmVD6AlSY3gniUqREss-ocl-Iimc47Us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 0. Нейронные сети и фреймворк PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм построения нейронных сетей (моделей)\n",
    "1. Подготовить наборы данных (**Datasets**) для обучения (**Train**), валидации (**Validation**) и проверки (**Test**) модели.\n",
    "2. Обеспечить механизм загрузки данных из набора (**Dataloaders**).\n",
    "3. Задать архитектуру нейронной сети = модель машинного обучения (**Model**).\n",
    "4. Определить прямой проход (**Forward**) по нейронной сети.\n",
    "5. Задать функцию ошибки (**Loss Function**) ([ссылка на перечень основных](https://medium.com/udacity-pytorch-challengers/a-brief-overview-of-loss-functions-in-pytorch-c0ddb78068f7)).\n",
    "6. Задать оптимизационный алгоритм (**Optimizer**) для параметров модели ([ссылка на документацию](https://pytorch.org/docs/master/optim.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм обучения нейронных сетей (моделей)\n",
    "1. Цикл по количеству эпох (**Epoch**) - полный проход по всему тренировочному набору данных.\n",
    "2. Цикл по частям набора данных (**Batches**) - входам и выходам (**Inputs** и **Outputs** или **Labels**).\n",
    "3. Посчитать результат прямого прохода - выход (**Model_Output**) или предсказание модели (**Predict**)\n",
    "4. Посчитать значение функции ошибки.\n",
    "5. Обнулить градиенты.\n",
    "6. Посчитать градиенты от ошибки (**Loss Backward**).\n",
    "7. Обновить параметры модели через шаг оптимизационного алгоритма (**Optimizer Step**).\n",
    "8. После обучения проверить модель на тестовом наборе данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: Тензоры (torch.Tensor)\n",
    "Тензоры в PyTorch - многомерные массивы, похожие на массивы Numpy, которые реализуют возможность вычисления градиентов и расчётов на видеокартах с поддержкой CUDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: Модели (torch.nn.Module)\n",
    "Модели в PyTorch - специальные классы для задания нейронных сетей или их частей, позволяющие автоматически создавать необходимое количество параметров и отслеживать их градиенты.<br>\n",
    "Модели строятся из объектов-слоёв (**torch.nn.Layer**) и определения прямого прохода по сети (forward), к выходам слоёв могут применяться функции (**torch.nn.functional**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: Наборы данных и загрузчики данных (torch.utils.data.Dataset и torch.utils.data.DataLoader)\n",
    "Для работы с входными данными для моделей предусмотрены два основных класса: Dataset и DataLoader. <br>\n",
    "Набор данных определяется классом Dataset, позволяющий поместить в себя всю логику по подготовке входных данных и реализующий методы получения элемента данных и размера набора данных (`__getitem__ и __len__`).<br>\n",
    "Работа с большими объёмами данных и получения их порциями (batch) определяется классом DataLoader, который определяет размер батча, стратегию получения батчей и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка для работы: импорты, задание наборов данных и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch             # основной пакет PyTorch\n",
    "import torchvision       # пакет с утилитами для компьютерного зрения (наборы данных, обученные модели и т.д.)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим устройство, на котором проводить расчёты\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим размер порции данных\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Загрузим встроенный в PyTorch MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='data', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='data', train=False, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# Создадим специальный класс DataLoader, который будет подавать изображения порциями по batch_size\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отобразим несколько изображений\n",
    "\n",
    "size = 28\n",
    "nrows, ncols = 8, 12\n",
    "images = np.zeros((size * nrows, size * ncols))\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        index = i * ncols + j\n",
    "        image = train_dataset[index][0]\n",
    "        images[i * size : i * size + size, j * size : j * size + size] = image\n",
    "        \n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(images, cmap='gray')\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Полносвязные нейронные сети (Fully-Connected Neural Networks, FCNN)\n",
    "Полносвязные нейронные сети - сети прямого распространения (Feed Forward Neural Network), в которых все нейроны каждого слоя связаны с нейронами предыдущего слоя. Соответственно, каждый такой слой называется полносвязным или линейным (**torch.nn.Linear**). ![](https://cdn-images-1.medium.com/max/1600/0*BinB4K8AxFwMKDbp)\n",
    "\n",
    "Такие сети отличаются большим количеством параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим модель полносвязной сети\n",
    "\n",
    "class FullyConnectedNetwork(torch.nn.Module):\n",
    "    \n",
    "    # Инициализация сети - задание параметров и объявление струтуры слоёв\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        \n",
    "        # Обязательно нужно вызвать инициализацию родителя\n",
    "        super().__init__()\n",
    "        \n",
    "        # Создаём экземпляр класса полносвязного слоя 1\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size) \n",
    "        \n",
    "        # Создаём экземпляр класса функции активации ReLU\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        # Создаём экземпляр класса полносвязного слоя 2\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    # Прямой проход по сети\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем модель и переместим на устройство для расчётов\n",
    "model = FullyConnectedNetwork(input_size=784, hidden_size=100, num_classes=10)\n",
    "model = model.to(device)\n",
    "\n",
    "# Зададим функцию ошибки (в нашем случае задача классификации, поэтому Кросс-Энтропия)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Зададим алгоритм оптимизации (например Adam)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Напечатаем модель\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Обучим модель\n",
    "\n",
    "# Зададим количество эпох - полных проходов по всему датасету\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Запустим цикл по эпохам\n",
    "for epoch in range(1, NUM_EPOCHS + 1): \n",
    "    \n",
    "    # Список для хранения ошибок на батче (batch)\n",
    "    train_loss = []\n",
    "    \n",
    "    # Цикл по порциям (батчам) обучающих данных\n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        # Переведём двумерные картинки в одномерные векторы с сохранением измерения batch\n",
    "        # Переместим изображения и метки к ним на устройство для расчётов\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "                \n",
    "        # 1. Выполним прямой проход по сети (модели)\n",
    "        output = model(images)\n",
    "        \n",
    "        # 2. Вычислим ошибку\n",
    "        loss = loss_function(output, labels)\n",
    "\n",
    "        # 3. Обнулим градиенты у параметров\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Выполним обратный проход (расчитаем градиенты)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Выполним шаг по алгоритму оптимизации\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Добавим значение ошибки в список\n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    # Напечатаем среднюю ошибку на эпохе обучения\n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Тестируем модель, для этого говорим PyTorch не считать градиенты\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # Заведём переменные для посчёта правильных и всего ответов\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Цикл по всем батчам данных из тестового набора\n",
    "    for images, labels in test_loader:\n",
    "        \n",
    "        # Приведём изображения в форму вектора и перенесём изображения и метки к ним на устройство\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Посчитаем предсказания модели по изображениям\n",
    "        outputs = model(images)\n",
    "                \n",
    "        # Выведем индексы выходных нейронов с маскимальным откликом\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        \n",
    "        # Посчитаем количество правильных и всего ответов\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    # Напечатаем процент правильных ответов из всех\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Свёрточные нейронные сети (Convolutional Neural Networks, CNN)\n",
    "Изображения - обычно многокональные, можно представить в следующем виде: ![](https://cdn-images-1.medium.com/max/1000/0*NI447zpXAZE5KT1X.png)\n",
    "Свёртка (**Convolution**) - специальная операция над изображением, во время которой происходит следующее: ![](https://cdn-images-1.medium.com/max/1000/1*5SpP-dbwdZvw5knRDlkIeg.gif)\n",
    "Подвыборка (**Pooling, Subsampling**) - специальная операция над изображением, во время которой происходит следующее: ![](https://cdn-images-1.medium.com/max/1000/0*-q55Kruj2uQcA9lu.gif)\n",
    "Свёрточные нейронные сети состоят из слоёв свёртки, слоёв подвыборки и в конце полносвязный слой, который отвечает за классификацию: ![](https://neurohive.io/wp-content/uploads/2018/10/Typical_cnn-768x236-570x175.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим модель свёрточной нейросети\n",
    "class ConvolutionalNetwork(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Первая свёртка + активация + подвыборка (используем класс Sequential для последовательности слоёв)\n",
    "        self.conv1 = torch.nn.Sequential(         # Входное изображение имеет размерность (1, 28, 28)\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=1,              # Количество входных каналов\n",
    "                out_channels=32,            # Количество фильтров (ядер свёртки)\n",
    "                kernel_size=5,              # Размер ядра\n",
    "                stride=1,                   # Шаг свёртки\n",
    "                padding=2,                  # Заходим за край изображения на 2 пикселя для сохранения размера\n",
    "            ),                              # В итоге выходная размерность после свёртки (16, 28, 28)\n",
    "            torch.nn.ReLU(),                      # Функция активации\n",
    "            torch.nn.MaxPool2d(kernel_size=2),    # Подвыборка из окон 2х2 - размерность на выходе (16, 14, 14)\n",
    "        )\n",
    "        # Вторая свёртка + активация + подвыборка\n",
    "        self.conv2 = torch.nn.Sequential(         # Входная размерность (16, 14, 14)\n",
    "            torch.nn.Conv2d(32, 64, 5, 1, 2),     # Выходная размерность (32, 14, 14)\n",
    "            torch.nn.ReLU(),                      # Функция активации\n",
    "            torch.nn.MaxPool2d(2),                # Выходная размерность (32, 7, 7)\n",
    "        )\n",
    "        self.out = torch.nn.Linear(64 * 7 * 7, 10)   # Полносвязный слой с выходом на 10 классов\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)           # Перевести выход вектор (batch_size, 32 * 7 * 7)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем модель и переместим на устройство для расчётов\n",
    "model = ConvolutionalNetwork().to(device)\n",
    "\n",
    "# Зададим функцию ошибки (в нашем случае задача классификации, поэтому Кросс-Энтропия)\n",
    "loss_function = torch.nn.CrossEntropyLoss()                     \n",
    "\n",
    "# Зададим алгоритм оптимизации (например Adam)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Напечатаем модель\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим модель\n",
    "\n",
    "# Зададим количество эпох - полных проходов по всему датасету\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Запустим цикл по эпохам\n",
    "for epoch in range(1, NUM_EPOCHS + 1): \n",
    "    \n",
    "    # Список для хранения ошибок на батче (batch)\n",
    "    train_loss = []\n",
    "    \n",
    "    # Цикл по порциям (батчам) обучающих данных\n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        # Переместим изображения и метки к ним на устройство для расчётов\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "                \n",
    "        # 1. Выполним прямой проход по сети (модели)\n",
    "        output = model(images)\n",
    "        \n",
    "        # 2. Вычислим ошибку\n",
    "        loss = loss_function(output, labels)\n",
    "\n",
    "        # 3. Обнулим градиенты у параметров\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Выполним обратный проход (расчитаем градиенты)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Выполним шаг по алгоритму оптимизации\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Добавим значение ошибки в список\n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    # Напечатаем среднюю ошибку на эпохе обучения\n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестируем модель, для этого говорим PyTorch не считать градиенты\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # Заведём переменные для посчёта правильных и всего ответов\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Цикл по всем батчам данных из тестового набора\n",
    "    for images, labels in test_loader:\n",
    "        \n",
    "        # Перенесём изображения и метки к ним на устройство\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Посчитаем предсказания модели по изображениям\n",
    "        outputs = model(images)\n",
    "                \n",
    "        # Выведем индексы выходных нейронов с маскимальным откликом\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        \n",
    "        # Посчитаем количество правильных и всего ответов\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    # Напечатаем процент правильных ответов из всех\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Упражнение\n",
    "0. Вынести в параметры модели количество ядер свёртки, размер свёртки с автоматическим расчётом padding и т.д.\n",
    "1. Написать хелперы для обучения и проверки моделей.\n",
    "2. Разбить датасет на обучающую и валидационную выборки и провести обучение с отслеживанием ошибок на обеих выборках.\n",
    "3. Поэксперементировать с batch_size, слоями, размерами ядер свёртки, количеством ядер и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Рекуррентные нейронные сети (Recurrent Neural Networks, RNN)\n",
    "[Ссылка на статью](https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79)\n",
    "![](https://cdn-images-1.medium.com/max/1000/1*o65pRKyHxhw7m8LgMbVERg.png)\n",
    "![](https://cdn-images-1.medium.com/max/1000/1*wFYZpxTTiXVqncOLQd_CIQ.jpeg)\n",
    "![](https://cdn-images-1.medium.com/max/1000/1*vhAfRLlaeOXZ-bruv7Ostg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гиперпараметры\n",
    "sequence_length = 28    # длина последовательности = количество строк в изображении\n",
    "input_size = 28         # размер элемента последовательности = количество столбцов в изображении\n",
    "hidden_size = 128       # размер внутреннего слоя (количество нейронов)\n",
    "num_layers = 2          # количество внутренних слоёв \n",
    "num_classes = 10        # размер выходного слоя = количество классов цифр\n",
    "batch_size = train_loader.batch_size\n",
    "learning_rate = 0.01    # скорость обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рекуррентная нейронная сеть (много в один, many to one)\n",
    "class RecurrentNetwork(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Создадим экзэмпляр класса LSTM ячейки\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Создадим экзэмпляр класса полносвязного слоя\n",
    "        self.fc = torch.nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Зададим начальное состояние внутренних слоёв и ячеек памяти (положено для класса LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Прямой проход через LSTM ячейки \n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: тензор размерности (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Подаём на полносвязный слой только элемент последовательности на последнем шаге - последнюю строку изображения\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем модель и переместим на устройство для расчётов\n",
    "model = RecurrentNetwork(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "# Зададим функцию ошибки (в нашем случае задача классификации, поэтому Кросс-Энтропия)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Зададим алгоритм оптимизации (например Adam)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Напечатаем модель\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим модель\n",
    "\n",
    "# Зададим количество эпох - полных проходов по всему датасету\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "# Запустим цикл по эпохам\n",
    "for epoch in range(1, NUM_EPOCHS + 1): \n",
    "    \n",
    "    # Список для хранения ошибок на батче (batch)\n",
    "    train_loss = []\n",
    "    \n",
    "    # Цикл по порциям (батчам) обучающих данных\n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        # Переместим изображения и метки к ним на устройство для расчётов\n",
    "        # Поскольку изображения имеют размерность (batch_size, channels=1, sequence_length, input_size),\n",
    "        # а в модели требуется размерность (batch_size, sequence_length, input_size), приведём размерность в соответствие\n",
    "        \n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 1. Выполним прямой проход по сети (модели)\n",
    "        output = model(images)\n",
    "        \n",
    "        # 2. Вычислим ошибку\n",
    "        loss = loss_function(output, labels)\n",
    "\n",
    "        # 3. Обнулим градиенты у параметров\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Выполним обратный проход (расчитаем градиенты)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Выполним шаг по алгоритму оптимизации\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Добавим значение ошибки в список\n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    # Напечатаем среднюю ошибку на эпохе обучения\n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестируем модель, для этого говорим PyTorch не считать градиенты\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # Заведём переменные для посчёта правильных и всего ответов\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Цикл по всем батчам данных из тестового набора\n",
    "    for images, labels in test_loader:\n",
    "        \n",
    "        # Перенесём изображения и метки к ним на устройство\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Посчитаем предсказания модели по изображениям\n",
    "        outputs = model(images)\n",
    "                \n",
    "        # Выведем индексы выходных нейронов с маскимальным откликом\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        \n",
    "        # Посчитаем количество правильных и всего ответов\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    # Напечатаем процент правильных ответов из всех\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 4. Автокодировшики (Autoencoders)\n",
    "![](https://camo.githubusercontent.com/96616324d5683a2e1efe9c469ca645e119b90602/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f333632333732302d356534363937376437663839303566392e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)\n",
    "![](https://blog.keras.io/img/ae/autoencoder_schema.jpg)\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*QM1b0gbKdMowkmyvO95DFA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим модель простого полносвязного автоэнкодера\n",
    "class SimpleAutoencoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "    \n",
    "        super().__init__()\n",
    "        \n",
    "        # Зададим архитекруту энкодера (шифровщика) - используем специальный класс Sequential\n",
    "        # Последовательно соеденим несколько линейных слоёв с ReLU активацией, выходной слой без активации\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28 * 28, 128),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(True), \n",
    "            torch.nn.Linear(64, 12), \n",
    "            torch.nn.ReLU(True), \n",
    "            torch.nn.Linear(12, 3)\n",
    "        )\n",
    "        \n",
    "        # Зададим архитекруту декодера (дешифровщика) - используем специальный класс Sequential\n",
    "        # Последовательно соеденим несколько линейных слоёв с ReLU активацией, выходной слой с гиперболическим тангенсом\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(3, 12),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(12, 64),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(64, 128),\n",
    "            torch.nn.ReLU(True), \n",
    "            torch.nn.Linear(128, 28 * 28), \n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "\n",
    "    # Зададим прямой проход по сети - энкодер и декодер\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Инициализируем модель и переместим на устройство для расчётов\n",
    "model = SimpleAutoencoder().to(device)\n",
    "\n",
    "# Зададим функцию ошибки (в нашем случае задача регрессии - выходной вектор приводим к входному, поэтому MSE)\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "# Зададим алгоритм оптимизации (например Adam)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Напечатаем модель\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим модель\n",
    "\n",
    "# Зададим количество эпох - полных проходов по всему датасету\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Запустим цикл по эпохам\n",
    "for epoch in range(1, NUM_EPOCHS + 1): \n",
    "    \n",
    "    # Список для хранения ошибок на батче (batch)\n",
    "    train_loss = []\n",
    "    \n",
    "    # Цикл по порциям (батчам) обучающих данных (метки в этой задаче не нужны)\n",
    "    for images, _ in train_loader:\n",
    "        \n",
    "        # Представим изображения в виде векторов и перенесём изображения на устройство\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        \n",
    "        # 1. Выполним прямой проход по сети (модели)\n",
    "        output = model(images)\n",
    "        \n",
    "        # 2. Вычислим ошибку\n",
    "        loss = loss_function(output, images)\n",
    "\n",
    "        # 3. Обнулим градиенты у параметров\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Выполним обратный проход (расчитаем градиенты)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Выполним шаг по алгоритму оптимизации\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Добавим значение ошибки в список\n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    # Напечатаем среднюю ошибку на эпохе обучения\n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестируем модель, для этого говорим PyTorch не считать градиенты\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # В этот раз будем просто считать среднюю ошибку на тестовых данных\n",
    "    test_loss = []\n",
    "    \n",
    "    # Цикл по всем батчам данных из тестового набора\n",
    "    for images, labels in test_loader:\n",
    "        \n",
    "        # Представим изображения в виде векторов и перенесём изображения на устройство\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        \n",
    "        # Посчитаем предсказания модели по изображениям\n",
    "        outputs = model(images)\n",
    "           \n",
    "        loss = loss_function(outputs, images)\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        \n",
    "    # Напечатаем среднюю ошибку\n",
    "    print('Mean error of the network on the 10000 test images:', np.mean(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вместо тестирования модели \n",
    "\n",
    "def decode(value1=0.0, value2=0.0, value3=0.0):\n",
    "    vector = [value1, value2, value3]\n",
    "    output = model.decoder(torch.Tensor(vector).to(device))\n",
    "    plt.figure(1, figsize=(3, 3))\n",
    "    plt.imshow(output.cpu().detach().numpy().squeeze().reshape(28, 28), cmap='gray')\n",
    "    plt.xticks(ticks=[], labels=[])\n",
    "    plt.yticks(ticks=[], labels=[])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "widgets.interact_manual(decode, value1=(-10.0, 10.0, 0.1), value2=(-10.0, 10.0, 0.1), value3=(-10.0, 10.0, 0.1));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
